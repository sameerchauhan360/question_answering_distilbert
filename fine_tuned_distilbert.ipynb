{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-24T13:32:16.982739Z","iopub.execute_input":"2024-09-24T13:32:16.983347Z","iopub.status.idle":"2024-09-24T13:32:17.996162Z","shell.execute_reply.started":"2024-09-24T13:32:16.983311Z","shell.execute_reply":"2024-09-24T13:32:17.995189Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -U transformers\n!pip install -U accelerate\n!pip install -U datasets\n!pip install -U bertviz\n!pip install -U umap-learn\n!pip install -U sentencepiece\n!pip install -U urllib3\n!pip install py7zr\n!pip install evaluate\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:32:17.998028Z","iopub.execute_input":"2024-09-24T13:32:17.998529Z","iopub.status.idle":"2024-09-24T13:34:26.229694Z","shell.execute_reply.started":"2024-09-24T13:32:17.998486Z","shell.execute_reply":"2024-09-24T13:34:26.228325Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.0)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting bertviz\n  Downloading bertviz-1.4.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: transformers>=2.0 in /opt/conda/lib/python3.10/site-packages (from bertviz) (4.44.2)\nRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.10/site-packages (from bertviz) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from bertviz) (4.66.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from bertviz) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bertviz) (2.32.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from bertviz) (2024.5.15)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from bertviz) (0.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0->bertviz) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.19.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->bertviz)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->bertviz) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->bertviz) (0.6.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bertviz) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bertviz) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bertviz) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bertviz) (2024.8.30)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->bertviz) (2.9.0.post0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->bertviz) (1.16.0)\nDownloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: botocore, bertviz\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.35.16\n    Uninstalling botocore-1.35.16:\n      Successfully uninstalled botocore-1.35.16\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.15.0 requires botocore<1.35.17,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bertviz-1.4.0 botocore-1.29.165\nCollecting umap-learn\n  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.14.1)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.2.2)\nRequirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.60.0)\nCollecting pynndescent>=0.5 (from umap-learn)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from umap-learn) (4.66.4)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn) (0.43.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\nDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pynndescent, umap-learn\nSuccessfully installed pynndescent-0.5.13 umap-learn-0.5.6\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (1.26.18)\nCollecting urllib3\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: urllib3\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.29.165 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed urllib3-2.2.1\nCollecting py7zr\n  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\nSuccessfully installed inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.1\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=73a956089cd99d0ec393296f2e066378b244bea707f3b8873048754b11b92430\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:08:56.433963Z","iopub.execute_input":"2024-09-24T14:08:56.434762Z","iopub.status.idle":"2024-09-24T14:08:56.439281Z","shell.execute_reply.started":"2024-09-24T14:08:56.434722Z","shell.execute_reply":"2024-09-24T14:08:56.438444Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:34:26.231248Z","iopub.execute_input":"2024-09-24T13:34:26.231589Z","iopub.status.idle":"2024-09-24T13:34:27.201293Z","shell.execute_reply.started":"2024-09-24T13:34:26.231555Z","shell.execute_reply":"2024-09-24T13:34:27.200481Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"squad = load_dataset('squad')\nsquad","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:34:27.203567Z","iopub.execute_input":"2024-09-24T13:34:27.204428Z","iopub.status.idle":"2024-09-24T13:34:31.735978Z","shell.execute_reply.started":"2024-09-24T13:34:27.204378Z","shell.execute_reply":"2024-09-24T13:34:31.735181Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc4ca2ba42a4ee4ae8d4626224e57ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9e03bdf77841699dfb6770b1e65ef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72381d5ff4b94e9a921fdf6480b1b96c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe83c327db34f76b5fde03d577e2e69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b6f818183040aa87585680ef54744a"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"squad['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:34:31.736974Z","iopub.execute_input":"2024-09-24T13:34:31.737437Z","iopub.status.idle":"2024-09-24T13:34:31.747772Z","shell.execute_reply.started":"2024-09-24T13:34:31.737402Z","shell.execute_reply":"2024-09-24T13:34:31.746296Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': '5733be284776f41900661182',\n 'title': 'University_of_Notre_Dame',\n 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess(batch):\n    return {\n        'input_text': [f\"question: {q} context: {c}\" for q, c in zip(batch['question'], batch['context'])],\n        'target_text': [\" \".join(ans['text']) if ans['text'] else \"\" for ans in batch['answers']]\n    }\n\ntokenized_squad = squad.map(preprocess, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:49:36.210544Z","iopub.execute_input":"2024-09-24T12:49:36.210849Z","iopub.status.idle":"2024-09-24T12:49:39.220931Z","shell.execute_reply.started":"2024-09-24T12:49:36.210817Z","shell.execute_reply":"2024-09-24T12:49:39.220074Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68c1fdc738744933829b8f990d8d19c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4488a201747d4c27aefeff30ad4db74e"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_squad","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:49:39.222014Z","iopub.execute_input":"2024-09-24T12:49:39.222326Z","iopub.status.idle":"2024-09-24T12:49:39.228120Z","shell.execute_reply.started":"2024-09-24T12:49:39.222293Z","shell.execute_reply":"2024-09-24T12:49:39.227233Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_text', 'target_text'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers', 'input_text', 'target_text'],\n        num_rows: 10570\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_squad['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:49:39.230224Z","iopub.execute_input":"2024-09-24T12:49:39.230548Z","iopub.status.idle":"2024-09-24T12:49:39.864243Z","shell.execute_reply.started":"2024-09-24T12:49:39.230517Z","shell.execute_reply":"2024-09-24T12:49:39.863263Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': '5733be284776f41900661182',\n 'title': 'University_of_Notre_Dame',\n 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n 'input_text': 'question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? context: Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n 'target_text': 'Saint Bernadette Soubirous'}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\nmodel_name = 'bert-base-cased'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:34:31.748956Z","iopub.execute_input":"2024-09-24T13:34:31.749318Z","iopub.status.idle":"2024-09-24T13:34:39.935597Z","shell.execute_reply.started":"2024-09-24T13:34:31.749275Z","shell.execute_reply":"2024-09-24T13:34:39.934648Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"356d2ef77f2e45f3af685124bf71ff7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a747a3c5ef474feba035f1eb665d9060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"964ea964b5164bfc859e986f3c4e7671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0653c04853aa4718ab77a5c2f8223705"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd4bcdd9ab7a4096b5f41b0e0de9d04e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2a12bc0d8248648a7ddc3d309a4d85"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def find_answer_token_idx(ctx_start, ctx_end, ans_start_char, ans_end_char, offset):\n\n    start_idx = 0\n    end_idx = 0\n\n    if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n        pass\n        # print(\"target is (0, 0)\")\n        # nothing else to do\n\n    else:\n        # find the start & end token position\n\n        i = ctx_start\n        for start_end_char in offset[ctx_start:]:\n            start, end = start_end_char\n\n            if start == ans_start_char:\n                start_idx = i\n\n            if end == ans_end_char:\n                end_idx = i\n                break\n\n            i += 1\n\n    return start_idx, end_idx","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:38:59.673936Z","iopub.execute_input":"2024-09-24T13:38:59.674783Z","iopub.status.idle":"2024-09-24T13:38:59.680861Z","shell.execute_reply.started":"2024-09-24T13:38:59.674742Z","shell.execute_reply":"2024-09-24T13:38:59.679957Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_length = 384\nstride = 128\n\ndef tokenizer_fn_train(batch):\n    questions = [q.strip() for q in batch['question']]\n\n    inputs = tokenizer(questions,\n                     batch['context'],\n                     max_length = max_length,\n                     stride = stride,\n                     truncation = 'only_second',\n                     return_overflowing_tokens = True,\n                     return_offsets_mapping = True,\n                     padding = 'max_length')\n\n    offset_mapping = inputs.pop('offset_mapping')\n    orig_sample_idxs = inputs.pop('overflow_to_sample_mapping')\n    answers = batch['answers']\n    start_idxs, end_idxs = [], []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = orig_sample_idxs[i]\n        answer = answers[sample_idx]\n\n        ans_start_char = answer['answer_start'][0]\n        ans_end_char = ans_start_char + len(answer['text'][0])\n\n        sequence_ids = inputs.sequence_ids(i)\n\n        ctx_start = sequence_ids.index(1)\n        ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n\n        start_idx, end_idx = find_answer_token_idx(\n        ctx_start,\n        ctx_end,\n        ans_start_char,\n        ans_end_char,\n        offset\n        )\n\n        start_idxs.append(start_idx)\n        end_idxs.append(end_idx)\n\n    inputs['start_positions'] = start_idxs\n    inputs['end_positions'] = end_idxs\n\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:39:01.153347Z","iopub.execute_input":"2024-09-24T13:39:01.154105Z","iopub.status.idle":"2024-09-24T13:39:01.163897Z","shell.execute_reply.started":"2024-09-24T13:39:01.154067Z","shell.execute_reply":"2024-09-24T13:39:01.162972Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = squad['train'].map(\n    tokenizer_fn_train,\n    batched = True,\n    remove_columns = squad['train'].column_names\n)\n\nlen(squad['train']), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:39:50.150902Z","iopub.execute_input":"2024-09-24T13:39:50.151828Z","iopub.status.idle":"2024-09-24T13:40:40.314537Z","shell.execute_reply.started":"2024-09-24T13:39:50.151788Z","shell.execute_reply":"2024-09-24T13:40:40.313631Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adaea5734963487da3067a876a86b7a9"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(87599, 88729)"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_fn_validation(batch):\n\n    questions = [q.strip() for q in batch['question']]\n\n    inputs = tokenizer(questions,\n                     batch['context'],\n                     max_length = max_length,\n                     stride = stride,\n                     truncation = 'only_second',\n                     return_overflowing_tokens = True,\n                     return_offsets_mapping = True,\n                     padding = 'max_length')\n\n    orig_sample_idxs = inputs['overflow_to_sample_mapping']\n    sample_ids = []\n\n    for i in range(len(inputs['input_ids'])):\n        sample_idx = orig_sample_idxs[i]\n        sample_ids.append(batch['id'][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs['offset_mapping'][i]\n        inputs['offset_mapping'][i] = [x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)]\n\n    inputs['sample_id'] = sample_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:41:34.004586Z","iopub.execute_input":"2024-09-24T13:41:34.005346Z","iopub.status.idle":"2024-09-24T13:41:34.012839Z","shell.execute_reply.started":"2024-09-24T13:41:34.005308Z","shell.execute_reply":"2024-09-24T13:41:34.011788Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"validation_dataset = squad['validation'].map(\n    tokenize_fn_validation,\n    batched = True,\n    remove_columns = squad['validation'].column_names\n)\n\nlen(squad['validation']), len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:41:35.294652Z","iopub.execute_input":"2024-09-24T13:41:35.295300Z","iopub.status.idle":"2024-09-24T13:41:43.658875Z","shell.execute_reply.started":"2024-09-24T13:41:35.295259Z","shell.execute_reply":"2024-09-24T13:41:43.657980Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a34d7bff814e24acaa7d5b89fc109d"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(10570, 10822)"},"metadata":{}}]},{"cell_type":"code","source":"n_largest = 20\nmax_answer_length = 30","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:39:47.935882Z","iopub.execute_input":"2024-09-24T14:39:47.936580Z","iopub.status.idle":"2024-09-24T14:39:47.941777Z","shell.execute_reply.started":"2024-09-24T14:39:47.936539Z","shell.execute_reply":"2024-09-24T14:39:47.940679Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(start_logits, end_logits, processed_dataset, orig_dataset):\n  sample_id2idxs = {}\n\n  for i, id_ in enumerate(processed_dataset['sample_id']):\n    if id_ not in sample_id2idxs:\n      sample_id2idxs[id_] = [i]\n\n    else:\n      sample_id2idxs[id_].append(i)\n\n  predicted_answers = []\n  for sample in tqdm(orig_dataset):\n    sample_id = sample['id']\n    context = sample['context']\n\n    best_score = float('-inf')\n    best_answer = None\n\n    for idx in sample_id2idxs[sample_id]:\n      start_logit = start_logits[idx]\n      end_logit = end_logits[idx]\n\n      offsets = processed_dataset[idx]['offset_mapping']\n\n      start_indices = (-start_logit).argsort()\n      end_indices = (-end_logit).argsort()\n\n      for start_idx in start_indices[:n_largest]:\n        for end_idx in end_indices[:n_largest]:\n\n          if offsets[start_idx] is None or offsets[end_idx] is None:\n            continue\n\n          if start_idx > end_idx:\n            continue\n\n          if end_idx - start_idx + 1 > max_answer_length:\n            continue\n\n          score = start_logit[start_idx] + end_logit[end_idx]\n\n          if score > best_score:\n            best_score = score\n\n            first_ch = offsets[start_idx][0]\n            end_ch = offsets[end_idx][1]\n\n            best_answer = context[first_ch : end_ch]\n\n    predicted_answers.append({'id' : sample_id, 'prediction_text' : best_answer})\n  true_answers = [{'id' : x['id'], 'answers' : x['answers']} for x in orig_dataset]\n\n  return metric.compute(predictions = predicted_answers, references = true_answers)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:16:05.713958Z","iopub.execute_input":"2024-09-24T14:16:05.714348Z","iopub.status.idle":"2024-09-24T14:16:05.726069Z","shell.execute_reply.started":"2024-09-24T14:16:05.714312Z","shell.execute_reply":"2024-09-24T14:16:05.725178Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\nargs = TrainingArguments(\n    'finedtuned-squad',\n    eval_strategy = 'no',\n    save_strategy = 'epoch',\n    learning_rate = 2e-5,\n    weight_decay = 0.01,\n    num_train_epochs = 3,\n    fp16 = True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:16:05.905589Z","iopub.execute_input":"2024-09-24T14:16:05.905880Z","iopub.status.idle":"2024-09-24T14:16:05.934225Z","shell.execute_reply.started":"2024-09-24T14:16:05.905849Z","shell.execute_reply":"2024-09-24T14:16:05.933480Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:16:06.122773Z","iopub.execute_input":"2024-09-24T14:16:06.123067Z","iopub.status.idle":"2024-09-24T14:16:06.127745Z","shell.execute_reply.started":"2024-09-24T14:16:06.123036Z","shell.execute_reply":"2024-09-24T14:16:06.126870Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset = train_dataset.shuffle(seed = 42).select(range(10_000)),\n    eval_dataset = validation_dataset,\n    tokenizer = tokenizer\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:16:07.508956Z","iopub.execute_input":"2024-09-24T14:16:07.509659Z","iopub.status.idle":"2024-09-24T14:16:07.534328Z","shell.execute_reply.started":"2024-09-24T14:16:07.509622Z","shell.execute_reply":"2024-09-24T14:16:07.533162Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:16:08.804685Z","iopub.execute_input":"2024-09-24T14:16:08.805058Z","iopub.status.idle":"2024-09-24T14:36:34.232676Z","shell.execute_reply.started":"2024-09-24T14:16:08.805021Z","shell.execute_reply":"2024-09-24T14:36:34.231746Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 20:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.395600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.331700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.114100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.786700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.775700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.498200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.446400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3750, training_loss=0.8775292846679688, metrics={'train_runtime': 1224.8283, 'train_samples_per_second': 24.493, 'train_steps_per_second': 3.062, 'total_flos': 5879177026560000.0, 'train_loss': 0.8775292846679688, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"outputs = trainer.predict(validation_dataset)\n\npredictions, _, _ = outputs\n\nstart_logits, end_logits = predictions\n\ncompute_metrics(start_logits,\n                end_logits,\n                validation_dataset,\n                squad['validation'])","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:39:52.812868Z","iopub.execute_input":"2024-09-24T14:39:52.813253Z","iopub.status.idle":"2024-09-24T14:42:44.953752Z","shell.execute_reply.started":"2024-09-24T14:39:52.813216Z","shell.execute_reply":"2024-09-24T14:42:44.952847Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"100%|██████████| 10570/10570 [00:24<00:00, 424.60it/s]\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'exact_match': 70.47303689687796, 'f1': 80.53739595254949}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('distil_bert')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:46:38.790893Z","iopub.execute_input":"2024-09-24T14:46:38.791300Z","iopub.status.idle":"2024-09-24T14:46:39.732094Z","shell.execute_reply.started":"2024-09-24T14:46:38.791263Z","shell.execute_reply":"2024-09-24T14:46:39.731123Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(tokenized_squad['validation'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline('question-answering', model = 'distil_bert', device = 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:47:04.663032Z","iopub.execute_input":"2024-09-24T14:47:04.663426Z","iopub.status.idle":"2024-09-24T14:47:04.915919Z","shell.execute_reply.started":"2024-09-24T14:47:04.663390Z","shell.execute_reply":"2024-09-24T14:47:04.914837Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"squad['train'][0]['question']","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:47:12.595879Z","iopub.execute_input":"2024-09-24T14:47:12.596273Z","iopub.status.idle":"2024-09-24T14:47:12.604031Z","shell.execute_reply.started":"2024-09-24T14:47:12.596234Z","shell.execute_reply":"2024-09-24T14:47:12.603207Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"},"metadata":{}}]},{"cell_type":"code","source":"squad['train'][0]['answers']","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:47:12.917219Z","iopub.execute_input":"2024-09-24T14:47:12.917525Z","iopub.status.idle":"2024-09-24T14:47:12.924771Z","shell.execute_reply.started":"2024-09-24T14:47:12.917494Z","shell.execute_reply":"2024-09-24T14:47:12.923951Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}"},"metadata":{}}]},{"cell_type":"code","source":"context = \"\"\"\nThe Amazon rainforest, often referred to as the \"lungs of the Earth,\" is the largest tropical rainforest in the world, spanning across several countries, including Brazil, Peru, and Colombia. It is home to an incredibly diverse array of wildlife, with millions of species of plants, animals, and insects. The rainforest plays a crucial role in regulating the global climate by absorbing carbon dioxide and producing oxygen. However, deforestation and illegal logging pose significant threats to this vital ecosystem, leading to habitat loss and contributing to climate change.\n\"\"\"\n\nquestion = \"What is one of the major threats to the Amazon rainforest mentioned in the paragraph\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:48:59.991558Z","iopub.execute_input":"2024-09-24T14:48:59.991951Z","iopub.status.idle":"2024-09-24T14:48:59.997560Z","shell.execute_reply.started":"2024-09-24T14:48:59.991913Z","shell.execute_reply":"2024-09-24T14:48:59.996561Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"pipe(question, context)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:56:37.786818Z","iopub.execute_input":"2024-09-24T14:56:37.787273Z","iopub.status.idle":"2024-09-24T14:56:37.818092Z","shell.execute_reply.started":"2024-09-24T14:56:37.787230Z","shell.execute_reply":"2024-09-24T14:56:37.816941Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"{'score': 0.7816429734230042,\n 'start': 434,\n 'end': 467,\n 'answer': 'deforestation and illegal logging'}"},"metadata":{}}]},{"cell_type":"code","source":"!zip distilbert.zip -r distil_bert/","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:55:08.266687Z","iopub.execute_input":"2024-09-24T14:55:08.267117Z","iopub.status.idle":"2024-09-24T14:55:31.667856Z","shell.execute_reply.started":"2024-09-24T14:55:08.267079Z","shell.execute_reply":"2024-09-24T14:55:31.666977Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"  adding: distil_bert/ (stored 0%)\n  adding: distil_bert/tokenizer_config.json (deflated 76%)\n  adding: distil_bert/special_tokens_map.json (deflated 42%)\n  adding: distil_bert/training_args.bin (deflated 51%)\n  adding: distil_bert/config.json (deflated 48%)\n  adding: distil_bert/tokenizer.json (deflated 70%)\n  adding: distil_bert/model.safetensors (deflated 7%)\n  adding: distil_bert/vocab.txt (deflated 49%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}